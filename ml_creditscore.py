# -*- coding: utf-8 -*-
"""ML_creditscore.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qy50d6vTmeqHfsQf66_yj6VlESY8oonR

# 1️ Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import LabelBinarizer

from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

"""# 2️ Load Data"""

# Load Data
train_df = pd.read_csv('/content/drive/MyDrive/Dataset (1)/train.csv', dtype={26: str})
test_df = pd.read_csv('/content/drive/MyDrive/Dataset (1)/test.csv', dtype={26: str})

test_df

train_df

"""# 3️ Drop Unnecessary Columns

"""

# Drop Unnecessary Columns
drop_columns = ['ID', 'Customer_ID', 'Name', 'SSN', 'Month']
train_df.drop(columns=drop_columns, inplace=True, errors='ignore')
test_df.drop(columns=drop_columns, inplace=True, errors='ignore')

"""# 4️ Handle Missing Values

"""

# Handle Missing Values
numeric_cols = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()
train_df[numeric_cols] = train_df[numeric_cols].apply(pd.to_numeric, errors='coerce')
test_df[numeric_cols] = test_df[numeric_cols].apply(pd.to_numeric, errors='coerce')
train_df.fillna(train_df.median(numeric_only=True), inplace=True)
test_df.fillna(test_df.median(numeric_only=True), inplace=True)

"""# 5️ Encode Categorical Variables"""

# Encode Categorical Variables
categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()
if 'Credit_Score' in categorical_cols:
    categorical_cols.remove('Credit_Score')

test_common_categorical = [col for col in categorical_cols if col in test_df.columns]
encoder = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
train_df[categorical_cols] = encoder.fit_transform(train_df[categorical_cols])
test_df[test_common_categorical] = encoder.transform(test_df[test_common_categorical])

scaler = StandardScaler()
if 'Credit_Score' in numeric_cols:
    numeric_cols.remove('Credit_Score')  # Ensure Credit_Score is not scaled
train_df[numeric_cols] = scaler.fit_transform(train_df[numeric_cols])
test_df[numeric_cols] = scaler.transform(test_df[numeric_cols])

# Ensure Labels Have Only "Good", "Poor", "Standard"
def clean_labels(label):
    if label not in ["Good", "Poor", "Standard"]:
        return "Standard"
    return label

train_df['Credit_Score'] = train_df['Credit_Score'].astype(str).apply(clean_labels)
if 'Credit_Score' in test_df.columns:
    test_df['Credit_Score'] = test_df['Credit_Score'].astype(str).apply(clean_labels)

"""# 6️ Train

"""

# Split Data
X = train_df.drop(columns=['Credit_Score'])
y = train_df['Credit_Score']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle Class Imbalance
print(X_train.isna().sum().sum())
X_train.fillna(X_train.median(numeric_only=True), inplace=True)

smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
}

for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{name} Accuracy:", accuracy_score(y_test, y_pred))
    print(f"{name} Classification Report:\n", classification_report(y_test, y_pred))
    print(f"{name} Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("-" * 50)



joblib.dump(model, f'{name.replace(" ", "_").lower()}_model.pkl')

# Before SMOTE
plt.figure(figsize=(8, 4))
sns.countplot(x=y, palette="viridis")
plt.title("Class Distribution Before SMOTE")
plt.xlabel("Credit Score")
plt.ylabel("Count")
plt.show()

# After SMOTE
plt.figure(figsize=(8, 4))
sns.countplot(x=y_train, palette="viridis")
plt.title("Class Distribution After SMOTE")
plt.xlabel("Credit Score")
plt.ylabel("Count")
plt.show()

importances = models["Random Forest"].feature_importances_
features = X.columns
plt.figure(figsize=(10, 5))
sns.barplot(x=importances, y=features, palette="coolwarm")
plt.title("Feature Importance (Random Forest)")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Good", "Poor", "Standard"], yticklabels=["Good", "Poor", "Standard"])
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

for name, model in models.items():
    y_pred = model.predict(X_test)
    plot_confusion_matrix(y_test, y_pred, name)

lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test)

plt.figure(figsize=(8, 6))
for name, model in models.items():
    if hasattr(model, "decision_function"):
        y_score = model.decision_function(X_test)
    else:
        y_score = model.predict_proba(X_test)

    for i in range(y_test_binarized.shape[1]):
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'{name} - Class {lb.classes_[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

import seaborn as sns

sampled_df = train_df.sample(1000)  # Take a smaller sample for faster visualization
sns.pairplot(sampled_df, hue="Credit_Score", palette="husl", diag_kind="kde")
plt.show()

plt.figure(figsize=(12, 6))
for i, col in enumerate(numeric_cols[:6]):  # Plot only a few to avoid clutter
    plt.subplot(2, 3, i + 1)
    sns.boxplot(x=train_df["Credit_Score"], y=train_df[col], palette="pastel")
    plt.title(f"{col} Distribution by Credit Score")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(train_df.corr(numeric_only=True), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y_train, palette="tab10", alpha=0.7)
plt.title("PCA Visualization of Data")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.show()

model_scores = {name: accuracy_score(y_test, model.predict(X_test)) for name, model in models.items()}

plt.figure(figsize=(8, 5))
sns.barplot(x=list(model_scores.keys()), y=list(model_scores.values()), palette="coolwarm")
plt.ylabel("Accuracy Score")
plt.title("Model Accuracy Comparison")
plt.ylim(0.5, 1.0)
plt.show()

